{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5cc9da-4806-4d72-9fae-0f7ebc57bc94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T13:43:34.201567Z",
     "start_time": "2025-04-05T13:43:28.766441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\pinar\\anaconda2\\lib\\site-packages (4.30.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from selenium) (0.29.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# Big Data Projekt_Gruppe 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e44cfe2f556cba1",
   "metadata": {},
   "source": [
    "### Lebensmittelpreisanalyse: Billa, Hofer & Interspar\n",
    "\n",
    "In diesem Projektabschnitt wurden **Produktdaten aus österreichischen Supermärkten (Billa, Hofer und Interspar)** gesammelt. Fokus lag auf den Kategorien:\n",
    "\n",
    "- Brot & Gebäck  \n",
    "- Kühlwaren  \n",
    "- Fleisch & Fisch  \n",
    "\n",
    "Mittels **Web Scraping** wurden die Preise und Produktnamen aus den jeweiligen Onlineshops extrahiert und als strukturierte **CSV-Dateien** gespeichert. Diese Dateien dienen als Grundlage für die spätere Analyse, Visualisierung und Vergleichbarkeit der Preise zwischen den Supermärkten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df9140457caed5e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-05T13:43:34.268974Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# Kategorie-URLs\n",
    "urls = [\n",
    "    \"https://www.interspar.at/shop/lebensmittel/wurst-fleisch-fisch/c/F3/\",\n",
    "    \"https://www.interspar.at/shop/lebensmittel/kuehlregal/c/F2/\",\n",
    "    \"https://www.interspar.at/shop/lebensmittel/brot-gebaeck/c/F6/\"\n",
    "]\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "base_url = \"https://www.interspar.at\"\n",
    "product_list = []\n",
    "\n",
    "try:\n",
    "    for url in urls:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "\n",
    "        while True:\n",
    "            # Warten auf Produkte\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"productBox\"))\n",
    "            )\n",
    "            time.sleep(1)\n",
    "\n",
    "            # HTML einlesen\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            product_boxes = soup.find_all('div', class_='productBox')\n",
    "\n",
    "            for box in product_boxes:\n",
    "                link_url = box.get('data-url')\n",
    "                link = base_url + link_url if link_url else \"\"\n",
    "\n",
    "                # Preis zusammensetzen aus zwei <label>\n",
    "                try:\n",
    "                    price_container = box.find('div', class_='actualPriceContainer')\n",
    "                    euros = price_container.find('label', class_='priceInteger').text.strip()\n",
    "                    cents = price_container.find('label', class_='priceDecimal').text.strip()\n",
    "                    price = f\"{euros},{cents} €\"\n",
    "                except:\n",
    "                    price = \"Kein Preis\"\n",
    "\n",
    "                # Produktname (zweiter Titel ist Name)\n",
    "                title_tags = box.find_all('div', class_='productTitle')\n",
    "                if len(title_tags) > 1 and title_tags[1].has_attr('title'):\n",
    "                    product_name = title_tags[1]['title'].strip()\n",
    "                elif title_tags and title_tags[0].has_attr('title'):\n",
    "                    product_name = title_tags[0]['title'].strip()\n",
    "                else:\n",
    "                    product_name = \"Kein Name\"\n",
    "\n",
    "                product_list.append({\n",
    "                    'Kategorie': url.split(\"/\")[-3],  # z. B. kuehlregal\n",
    "                    'Produkt': product_name,\n",
    "                    'Preis': price,\n",
    "                    'Link': link\n",
    "                })\n",
    "\n",
    "            # Weiterblättern, falls möglich\n",
    "            try:\n",
    "                next_button = driver.find_element(By.CSS_SELECTOR, 'a[title=\"nächste Seite\"]')\n",
    "                if \"disabled\" in next_button.get_attribute(\"class\"):\n",
    "                    break\n",
    "                next_button.click()\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                break\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "# Speichern als CSV\n",
    "with open('interspar_kategorien.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['Kategorie', 'Produkt', 'Preis', 'Link'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(product_list)\n",
    "\n",
    "print(f\"{len(product_list)} Produkte erfolgreich gespeichert in 'interspar_kategorien.csv'\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Produkte gefunden auf https://shop.billa.at/kategorie/kuehlwaren-13841\n",
      "30 Produkte gefunden auf https://shop.billa.at/kategorie/brot-und-gebaeck-13766\n",
      "60 Produkte gespeichert.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# Liste der Billa-Kategorien\n",
    "urls = [\n",
    "    \"https://shop.billa.at/kategorie/kuehlwaren-13841\",\n",
    "    \"https://shop.billa.at/kategorie/brot-und-gebaeck-13766\"\n",
    "]\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "product_list = []\n",
    "\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.CLASS_NAME, \"ws-product-item-base\"))\n",
    "    )\n",
    "    time.sleep(3)\n",
    "\n",
    "    products = driver.find_elements(By.CLASS_NAME, \"ws-product-item-base\")\n",
    "    print(f\"{len(products)} Produkte gefunden auf {url}\")\n",
    "\n",
    "    for product in products:\n",
    "        # Produktname aus Attribut\n",
    "        try:\n",
    "            product_name = product.get_attribute(\"data-teaser-name\")\n",
    "        except:\n",
    "            product_name = \"Kein Name\"\n",
    "\n",
    "        # Preis extrahieren\n",
    "        try:\n",
    "            price = product.find_element(By.CLASS_NAME, \"ws-product-price-type__value\").text.strip()\n",
    "        except:\n",
    "            price = \"Kein Preis\"\n",
    "\n",
    "        product_list.append({'Produkt': product_name, 'Preis': price, 'Seite': url})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# CSV speichern\n",
    "with open('billa_mehrere_seiten.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['Produkt', 'Preis', 'Seite'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(product_list)\n",
    "\n",
    "print(f\"{len(product_list)} Produkte gespeichert.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e65e58a1b7e04493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gefundene Produkte: 100\n",
      "100 Produkte gespeichert in 'hofer_produkte.csv'\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# Starte Browser\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.hofer.at/de/sortiment/produktsortiment/fleisch-und-fisch.html\")\n",
    "\n",
    "# Warte bis Produktkarten sichtbar sind\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.CLASS_NAME, \"item.plp_product\"))\n",
    ")\n",
    "time.sleep(2)\n",
    "\n",
    "# Finde alle Produkte\n",
    "products = driver.find_elements(By.CLASS_NAME, \"item.plp_product\")\n",
    "print(f\"Gefundene Produkte: {len(products)}\")\n",
    "\n",
    "product_list = []\n",
    "\n",
    "for product in products:\n",
    "    # Produktname aus h2\n",
    "    try:\n",
    "        name_tag = product.find_element(By.CLASS_NAME, \"product-title\")\n",
    "        product_name = name_tag.text.strip()\n",
    "    except:\n",
    "        product_name = \"Kein Name\"\n",
    "\n",
    "    # Preis aus span\n",
    "    try:\n",
    "        price_tag = product.find_element(By.CLASS_NAME, \"at-product-price_lbl\")\n",
    "        price = price_tag.text.strip()\n",
    "    except:\n",
    "        price = \"Kein Preis\"\n",
    "\n",
    "    product_list.append({'Produkt': product_name, 'Preis': price})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Export als CSV\n",
    "with open('hofer_produkte.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['Produkt', 'Preis'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(product_list)\n",
    "\n",
    "print(f\"{len(product_list)} Produkte gespeichert in 'hofer_produkte.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "635cbbdf-9001-4d9c-a213-4d49738d7b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Produkte auf Seite in Kategorie: fleisch-und-fisch.html\n",
      "100 Produkte auf Seite in Kategorie: kuehlung.html\n",
      "100 Produkte auf Seite in Kategorie: vorratsschrank.html\n",
      "300 Produkte aus allen Kategorien gespeichert in 'hofer_kategorien.csv'\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# Kategorien-URLs\n",
    "urls = [\n",
    "    \"https://www.hofer.at/de/sortiment/produktsortiment/fleisch-und-fisch.html\",\n",
    "    \"https://www.hofer.at/de/sortiment/produktsortiment/kuehlung.html\",\n",
    "    \"https://www.hofer.at/de/sortiment/produktsortiment/vorratsschrank.html\"\n",
    "]\n",
    "\n",
    "# Starte Browser\n",
    "driver = webdriver.Chrome()\n",
    "product_list = []\n",
    "\n",
    "try:\n",
    "    for url in urls:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                # Warte auf Produkte\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_all_elements_located((By.CLASS_NAME, \"item.plp_product\"))\n",
    "                )\n",
    "                time.sleep(1)\n",
    "\n",
    "                products = driver.find_elements(By.CLASS_NAME, \"item.plp_product\")\n",
    "                print(f\"{len(products)} Produkte auf Seite in Kategorie: {url.split('/')[-1]}\")\n",
    "\n",
    "                for product in products:\n",
    "                    # Produktname\n",
    "                    try:\n",
    "                        name_tag = product.find_element(By.CLASS_NAME, \"product-title\")\n",
    "                        product_name = name_tag.text.strip()\n",
    "                    except:\n",
    "                        product_name = \"Kein Name\"\n",
    "\n",
    "                    # Preis\n",
    "                    try:\n",
    "                        price_tag = product.find_element(By.CLASS_NAME, \"at-product-price_lbl\")\n",
    "                        price = price_tag.text.strip()\n",
    "                    except:\n",
    "                        price = \"Kein Preis\"\n",
    "\n",
    "                    # Zur Liste hinzufügen\n",
    "                    product_list.append({\n",
    "                        'Kategorie': url.split('/')[-1].replace('.html', ''),\n",
    "                        'Produkt': product_name,\n",
    "                        'Preis': price\n",
    "                    })\n",
    "\n",
    "                # Weiter-Button prüfen\n",
    "                next_button = driver.find_element(By.CLASS_NAME, \"pagination-next\")\n",
    "                if \"disabled\" in next_button.get_attribute(\"class\"):\n",
    "                    break\n",
    "                else:\n",
    "                    next_button.click()\n",
    "                    time.sleep(2)\n",
    "\n",
    "            except:\n",
    "                break\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "# Speichere alles als CSV\n",
    "with open('hofer_kategorien.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['Kategorie', 'Produkt', 'Preis'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(product_list)\n",
    "\n",
    "print(f\"{len(product_list)} Produkte aus allen Kategorien gespeichert in 'hofer_kategorien.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b887911707a010e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T16:52:26.512592Z",
     "start_time": "2025-04-19T16:52:12.938486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\pinar\\anaconda2\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: pymongo in c:\\users\\pinar\\anaconda2\\lib\\site-packages (4.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from pymongo) (2.7.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pinar\\anaconda2\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3b1e7de98c3b84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 Datensätze aus 'Billa' importiert.\n",
      "300 Datensätze aus 'Hofer' importiert.\n",
      "240 Datensätze aus 'Interspar' importiert.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Verbindung zur MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"supermarkt_preise\"]\n",
    "collection = db[\"lebensmittel\"]\n",
    "\n",
    "# Optional: Bestehende Daten vorher löschen\n",
    "collection.delete_many({})\n",
    "\n",
    "# Deine Dateien + zugehöriger Supermarktname\n",
    "files_with_market = {\n",
    "    \"C:/Users/pinar/DataspellProjects/BDProject/Projekt/lebensmittelpreise-bigdata/data/billa_mehrere_seiten.csv\": \"Billa\",\n",
    "    \"C:/Users/pinar/DataspellProjects/BDProject/Projekt/lebensmittelpreise-bigdata/data/hofer_kategorien.csv\": \"Hofer\",\n",
    "    \"C:/Users/pinar/DataspellProjects/BDProject/Projekt/lebensmittelpreise-bigdata/data/interspar_kategorien.csv\": \"Interspar\"\n",
    "}\n",
    "\n",
    "# Alle in dieselbe Collection importieren\n",
    "for filepath, supermarkt in files_with_market.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        df[\"Supermarkt\"] = supermarkt  \n",
    "        data = df.to_dict(orient=\"records\")\n",
    "        collection.insert_many(data)\n",
    "        print(f\"{len(data)} Datensätze aus '{supermarkt}' importiert.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei Datei {filepath}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ad2df-757b-48fe-a094-b711e8ac7a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
